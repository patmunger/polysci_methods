---
title: "Ordinal Model"
author: "Patrick Munger"
date: "Fall 2024"
output: html_document
---

# Agenda

1.  Estimate ordinal logit models (function `polr` from `MASS` package)
2.  Testing assumptions (Brandt for Proportional Odds)
3.  Estimate models that relax assumption (`clm` and `vglm`)
4.  Compute and plot predicted probabilities (function `ggpredict` from `ggeffects` package)
5.  Compute and plot Average Marginal Effects (function `avg_slopes` from `marginaleffects` package)

# Preliminaries

```{r include=FALSE}
# Set seed for replicability
set.seed(1234)
```

```{r include=FALSE}
# Load necessary libraries
library(tidyverse)        # Data manipulation and plotting
library(stargazer)        # LaTeX tables
library(MASS)             # For polr function
library(brant)            # For Brant test
library(ggeffects)        # For marginal effects and predictions
library(carData)          # Built-in datasets (including WVS)
library(marginaleffects)  # For computing marginal effects 
library(car)              # For PoTest
library(ordinal)          # For cumulative link model 
library(VGAM)             # For generalized ologit 
```

# Data

```{r}
# Load the World Values Survey data from carData package 
data("WVS", package = "carData")
world_values <- WVS

# Check the dataset
summary(world_values)

# WVS: World Values Survey
# - poverty: Ordered outcome of "Do you think what the government is doing for poverty is about right, too much, or too little?" 
#   1 = Too Little, 2 = About Right, 3 = Too Much
# - religion: Member of a religion: 1 = no, 2 = yes
# - degree: Held a university degree: 1 = no, 2 = yes
# - country: Australia(1), Norway(2), Sweden(3), USA(4)
# - age: Continuous variable
# - gender: 1 = female, 2 = male

# Check variable types to makes sure they are appropriate
# We need to make sure our ordinal variables are in fact ordered 
str(world_values)
```

# Estimate Model

Now we estimate an ordered logit with the `polr()` function from the `MASS` package. We will estimate the effects of religion (binary), country (4 categories - Australia as reference), age (discrete numeric), and gender (binary) on the opinion on government poverty alleviation efforts (3 levels).

Syntax for specifying the model is very similar to `lm()` or `glm()`. Note that `Hess = TRUE` indicates that we want to variance-covariance matrix to be returned with the model. This is necessary for uncertainty estimates - so we will need this to get standard errors or p-values.

```{r}
# Running the Ordered Logit Model
world_values_fit <- polr(poverty ~ religion + degree + country + age + gender, 
                         data = world_values, Hess = TRUE)

# Summarizing the model results - this will return standard errors
summary(world_values_fit)
```

```{r}
# To get significance stars, we can create a stargazer table of model results
stargazer(world_values_fit, type = "text")
```

# Parallel Lines (Proportional Odds) Assumption

## Brand Test for Assumption Violations

While this assumption is sometimes ignored, for an unbiased ologit, is is necessary that the effects of each IV on the DV be constant across the levels of the DV. So in our case the effect of any one of our IVs should be the same moving from "Too Little" to "About Right" as it is moving from "About Right" to "Too little". Theoretically, we can imagine why this assumption would very often be violated. We can use the Brandt test from the `Brandt` package or the Proportional Odds test from the `car` package to test this assumption globally and for each predictor. These two tests perform the same function, but I find the `PoTest` more informative as it returns the betas for the predictors under the assumption of proportional odds and differentiated across cutpoints. This lets us see how the test assess if there are statistically significant differences between the betas at the different levels.

```{r}
# Brant Test 
brant_test <- brant(world_values_fit)
brant_test
```

```{r}
# Proportional Odds Test
poTest(world_values_fit)
```

The null hypothesis is that the assumption holds. So, significant p-values indicate that the assumption is violated for those variables. It looks like the assumption is violated for our religion and country variable.

## Models for Relaxing the Assumption

### Cumulative Link Model

One model for relaxing the PO assumption is the cumulative link function. This model allows effects to vary across DV categories for specified IVs but will not explicitly model separate betas across cutpoints. Instead it adjusts the cutpoints (thresholds) themselves for the specified variables. We can estimate this model with `clm()` from the `ordinal` package. The variables for which the PO assumption should be relaxed, we specify with the nominal argument.

The mechanics of the model are explained here: <https://cran.r-project.org/web/packages/ordinal/vignettes/clm_article.pdf>

```{r}
# Fit a cumulative link model
world_values_clm <- clm(poverty ~ degree + age + gender, 
               nominal = ~ religion + country, 
               data = world_values)

summary(world_values_clm)
```

You will see that with the `clm`, the variables we identified as having non-proportional effects will not be estimated for beta coefficients. Instead, separate threshold coefficients are estimates.

I was unable to get these threshold coefficients to print with p-values or significance stars in a stargazer table, but here's a way I found with the `broom` and `sjPlot` packages:

```{r}
# Extract threshold coefficients
thresholds <- summary(world_values_clm)$alpha

# Extract the coefficients for IVs
coefs <- coef(summary(world_values_clm))

# Combine them into one table
combined_results <- rbind(coefs, thresholds)

# Print the combined table
print(combined_results)

```

```{r}
library(broom)

# Tidy the model results
tidy_clm <- tidy(world_values_clm)

# Print the tidy table with coefficients and thresholds
print(tidy_clm)

```

By default `sjPlot` will exponentiate the coefficients into odds ratios. To get the raw coefficents (log odds) we can include the `transform = NULL` arguement. For assessing direction and significance of the effects we will look at the log odds

```{r}
library(sjPlot)
# Create a table with both coefficients and threshold estimates
tab_model(world_values_clm, show.se = TRUE, show.ci = FALSE)
```

The threshold coefficients for variables violating the proportional odds assumption adjust the location of the cutpoints for specific levels of the IVs. For instance:

-   The statistically significant and positive log odds for `Too Little|About Right.religionyes` (-0.10) indicates that the cutpoint separating "Too Little" and "About Right" shifts down for people who identify with a religion. *From What I understand*, this means religious people are more likely to perceive poverty as "About Right" rather than "Too Little" compared to people without religious affiliation.

-   The statistically significant and negative log odds for `About Right|Too Much.countryNorway` (0.12) indicates that the cutpoint separating "About Right" and "Too Much" shifts up for Norwegians as apposed to the baseline Australians category. This means Norwegians are less likely to move from "About Right" to "Too Much\* as compared to Australians.

### Generalized Ologit

An alternative approach to modeling non-proportional odds is a generalized ordinal model that will explicitly estimate and print separate betas for the different cutpoints (just two in our case, as we have a 3-level DV) for the variables in which we relax the assumption. We can estimate this model with `vglm()` from the `VGAM` package. We include all our predictors, then specify the ones for which the proportional odds assumption is MET with `family = cumulative(parallel = )`.

Note the warning messages for convergence issues. In factm, when we include age as a parallel variable, the model fails to estimate.

```{r}
world_values_gologit <- vglm(poverty ~ religion + degree + country + age + gender,
                             family = cumulative(parallel = ~ degree + gender),
                             data = world_values)

summary(world_values_gologit)
```

# Predicted Probabilities

Predicted probabilities tell us the predicted probabilities of each level of our DV occuring at different values of our IVs.

## Generate Probabilities

To compute Predicted Probabilities, we can use the `ggpredict()` fuction from the `ggeffects` package. For simplicity, it makes since to specify which variable we want to view the PPs for with the 'term' argument. By default, the other variables will be held at their mean (for numeric) and their mode (for factor), but we can also specify certain levels of the other variables if we wish.

```{r}
# Fetch predicted probabilities across levels of "religion" (binary IV)
religion_pred <- ggpredict(world_values_fit, terms = "religion")
religion_pred
```

```{r}
# Predicted probabilities across levels of "degree" (binary IV)
degree_pred <- ggpredict(world_values_fit, terms = "degree")
degree_pred
```

```{r}
# Predicted probabilities across levels of "country" (categorical IV)
country_pred <- ggpredict(world_values_fit, terms = "country")
country_pred
```

```{r}
# Predicted probabilities for a continuous variable (age)
age_pred <- ggpredict(world_values_fit, terms = "age")
age_pred
```

It defaults to fetching PPs for every 10 years of age, but we can specify our own values:

```{r}
# Generate predicted probabilities for specific ages (e.g., 25, 35, 45, and 55)
age_pred2 <- ggpredict(world_values_fit, terms = "age [25, 35, 45, 55]")
age_pred2
```

Here is how we can manually set the levels that other IVs are held at with thw `condition` arguement:

```{r}
# Set other IVs to specific values, rather than being held at their mean (continuous) or mode (factor)
# Set religion to "yes", gender to "female", and country to "USA"
age_pred_custom <- ggpredict(world_values_fit, 
                             terms = "religion", 
                             condition = c(degree = "yes", gender = "female", country = "USA"))
age_pred_custom
```

## Plot Probabilities

We can use R's `plot()` function to plot the probabilities we got from with `ggpredict`. Since we have a 3-level DV, each IV will produce 3 plots, labeled by level of the DV. These plots will look different for factor and numeric IVs.

```{r}
# Plot predicted probabilities for "religion"
plot(religion_pred) +
  labs(title = "Predicted Probabilities of Poverty Opinion by Religion",
       x = "Religion", 
       y = "Predicted Probability")

# Plot predicted probabilities for "degree"
plot(degree_pred) +
  labs(title = "Predicted Probabilities of Poverty Opinion by Degree",
       x = "Degree", 
       y = "Predicted Probability")

# Plot predicted probabilities for "country"
plot(country_pred) +
  labs(title = "Predicted Probabilities of Poverty Opinion by Country",
       x = "Country", 
       y = "Predicted Probability")

# Plot predicted probabilities for "age" with confidence intervals
plot(age_pred) +
  labs(title = "Predicted Probabilities of Poverty Opinion by Age",
       x = "Age", 
       y = "Predicted Probability")
```

# Average Marginal Effects (AMEs)

Marginal effects tell us the change in predicted probabilities for a change in our IV. For continuous IVs, this is the partial derivative of the predicted probability with respect to the IV. For categorical variables, it is the change in the predicted probability as we move from one category to the other.

# Compute AMEs

We can use the `marginaleffects` package to compute marginal effects for each of our predictors. We can use the `slopes()` function to get the effects across all observations, but this will take R a long time and be completely overwhelming to interpret. Instead, we can use `avg_slopes()` to compute average marginal effects. The will average the marginal effects across all observations.

```{r}
# Compute AMEs for the entire model
meffects <- avg_slopes(world_values_fit)
meffects
```

```{r}
# Compute AMEs for religion
ames_religion <- avg_slopes(world_values_fit, variables = "religion")
ames_religion
```

```{r}
# Compute AMEs for Degree
ames_degree <- avg_slopes(world_values_fit, variables = "degree")
ames_degree
```

```{r}
# Compute AMEs for Age
ames_age <- avg_slopes(world_values_fit, variables = "age")
ames_age
```

```{r}
# Compute AME for Country
ames_country <- avg_slopes(world_values_fit, variables = "country")
ames_country
```

## Plot AMEs

We can use `ggplot()` to plot our AMEs.

```{r}
# Plot Religion
ggplot(ames_religion, aes(x = group, y = estimate, ymin = conf.low, ymax = conf.high)) +
  geom_point(size = 4, color = "blue") +   # Plot the point estimate
  geom_errorbar(width = 0.2, color = "blue") +  # Add error bars for the confidence intervals
  labs(title = "Average Marginal Effects of Religion on Poverty Opinion",
       x = "Poverty Opinion Category",
       y = "Average Marginal Effect") +
  theme_minimal()  

# Plot Degree
ggplot(ames_degree, aes(x = group, y = estimate, ymin = conf.low, ymax = conf.high)) +
  geom_point(size = 4, color = "blue") +   # Plot the point estimate
  geom_errorbar(width = 0.2, color = "blue") +  # Add error bars for the confidence intervals
  labs(title = "Average Marginal Effects of Degree on Poverty Opinion",
       x = "Poverty Opinion Category",
       y = "Average Marginal Effect") +
  theme_minimal()  

# Plot Age
ggplot(ames_age, aes(x = group, y = estimate, ymin = conf.low, ymax = conf.high)) +
  geom_point(size = 4, color = "blue") +   # Plot the point estimate
  geom_errorbar(width = 0.2, color = "blue") +  # Add error bars for the confidence intervals
  labs(title = "Average Marginal Effects of Age on Poverty Opinion",
       x = "Poverty Opinion Category",
       y = "Average Marginal Effect") +
  theme_minimal()  

```

Note, we can also plot for the country variable, but I was unable to produce a plot that neatly color coded the bars for each country pairing.
