---
title: "Week 11: Outliers"
author: "Ozlem Tuncel; Patrick Munger"
date: "Spring 2025"
output: html_document
---

# Week 11: Outliers

## Agenda

-   Import and clean data
-   Estimate models
-   Residuals vs Fitted plot
-   Cook's D

## Setup

### Load libraries:

There might be some new packages here. Make sure you have them all installed before loading them.

```{r}
library(tidyverse)  
library(stargazer)
library(car)
library(olsrr)     
```

### Import and clean data

Here were are using the V-dem version 12 dataset again.

Remember to make sure your working directory is set to the directory where your data file is. Check current working with `getwd()` and change if necessary with `setwd("path to data directory goes here")`, replacing with the actual with to your data directory.

Note: when importing the data, only use /data if the file is in a directory within your working directory called "data". If your data file is located directly in your working directory simply specify the file name - "vdem12.rds"

We'll use the cross-sectionl data from year $2000$ this week, selecting for the following variables. We'll also drop NAs in the dataframe itself so that the indexing for the observations and residuals line up.

```{r}
cs_data <- readRDS("data/vdem12.rds") |> 
  filter(year == "2000") |> 
  rename(democracy = v2x_polyarchy, 
         gdp_per_capita = e_gdppc,
         urbanization = e_miurbani,
         energy_income_pc = e_total_resources_income_pc) |>
  select(country_name, year, democracy, gdp_per_capita, urbanization, energy_income_pc) |>
  drop_na()
```

## Estimate Models

```{r, warning = FALSE}
cs_model <- lm(democracy ~ gdp_per_capita + urbanization + energy_income_pc, data = cs_data)

stargazer(cs_model, type = "text", report = "vcstp*",
          title = "Predictors of democracy in the US")
```

## Inspect Fitted and Residual values

We can use the fitted() and residual() fucntions to print our lists of fitted values and residuals from our model.

Our list of fitted values (predicted $Y$ or $\hat{y}$ values):

```{r}
fitted(cs_model) 
```

Our vector of residuals (distance between observed $Y$ values ($Y_i$) and predicted $Y$ values ($\hat{y}$)):

```{r}
residuals(cs_model) 
```

Alternatively, we can manually pull out the vectors from the model's list components with the `$` operator (`cs_data$fitted` and `cs_data$residuals`)

Now let's use the `which.max()` function to identify the largest residual in terms of its absolute value, which we can get with the `abs()` function.

```{r}
which.max(abs(residuals(cs_model))) 
```

Here we see that the largest residual (absolute value) comes from observation $152$ is. Refering back to our entire list of residuals, we can see it's value. Now let's visualize our residuals with some of the diagnostic options from the `which =` arguement of the `plot()` function and see if this observations pops up as an outlier.

```{r}
plot(cs_model, which = 1, add.smooth = FALSE) 
plot(cs_model, which = 2, add.smooth = FALSE)
plot(cs_model, which = 3, add.smooth = FALSE)
```

## DFBETAS

We can get the matrix of dfbetas with the base-R `dfbetas()` function:

```{r}
dfbetas(cs_model)
```

This is a lot to make sense of, so let's define a function that prints the top 5 for each predictor.

```{r}
dfb <- dfbetas(cs_model)

apply(dfb, 2, function(col) {
  idx <- order(abs(col), decreasing = TRUE)[1:5]
  data.frame(DFBETA = col[idx])
})
```

We see similar observations popping up as in the residual diagnostics above.

We can also plot them for each predictor with the `ols_plot_dfbetas()` function from the `olsrr` package. This will also flag outliers over the $\frac{2}{\sqrt{n}}$ threshold.

```{r}
ols_plot_dfbetas(cs_model)
```

## Cook's Distance

We can calculate the Cook's Distances for each observation with the `cooks.distance()` function from the `car` package. Let's assign the resulting vector to an object for use in the next step.

```{r}
cooksD <- cooks.distance(cs_model)
cooksD
```

Let's pull out some of the most influencial observations from this vector object. We'll use the indexing operator `[ ]` to pull out values that are $>$ than 3 times the mean Cook'D value.

```{r}
cooksD[(cooksD > (3 * mean(cooksD, na.rm = TRUE)))]
```

We can also use `which = 4` in the `plot()` Cook's D values:

```{r}
plot(cs_model, which = 4, add.smooth = FALSE)
```

Or from with the `ols_plot_cooksd_bar()` and `ols_plot_cooksd_chart()` functions from `olsrr` which compute a threshold ($4/n$) to flag outliers.

```{r}
ols_plot_cooksd_bar(cs_model)
ols_plot_cooksd_chart(cs_model)
```

In both of these we see that out largest residual (observation $152$) is by far the most influential.

## Other diagnostics

### COVRATIO

We can get COVRATIO values for each observation with the `covratio()` function from base R. Within the function, we include the `infl =` arguement in which we get the influence of our model observations with `lm.influence()` and the `res =` arguement in which we get our model residuals with `residuals()`. 

```{r}
cov_ratios <- covratio(cs_model, 
                       infl = lm.influence(cs_model),
                       res = residuals(cs_model))
cov_ratios
```

Let's look at which observations have $COVRATIO < 1$, meaning they decrease the precision of our estimates (increase S.E. estimates).

```{r}
low_covratios <- which(cov_ratios < 1)

print(cov_ratios[low_covratios])
```

Now let's look at the top 10 values, those which increase the precision of our estimates (decrease S.E. estimates).

```{r}
high_covratios <- order(cov_ratios, decreasing = TRUE)[1:10]

print(cov_ratios[high_covratios])
```


### Outlier Test

the `outlierTest()` from the `car` package "Reports the Bonferroni p-values for testing each observation in turn to be a mean-shift outlier, based Studentized residuals in linear (t-tests), generalized linear models (normal tests), and linear mixed models." See [here](https://www.rdocumentation.org/packages/car/versions/3.1-3/topics/outlierTest) for documentation.

```{r}
outlierTest(cs_model, cutoff= 0.05)
```

Again, $152$ pops up. Let's use the indexing operator (specifying the row and all columns) again to see what country observation $152$ is:

```{r}
cs_data[152, ]
```

It's the UAE. I suspect that this is not due to coding or measurement error, but due to the UAE's uniqueness across our variables (low democracy, high energy income, gdp, and urbanization) which we can see if we sort our rows by column values.

```{r}
View(cs_data)
```

Thus, we probably have theoretical reason to leave the UAE in. But let's say we suspect it is due to error or is theoretically unimportant. In this case, we can drop it. We know it is observation 152 in our filtered df, so let's drop that.

```{r}
subset_data <- cs_data[-152, ] 
```

or in tidy language:

```{r}
subset_data <- cs_data %>% filter(!country_name == "United Arab Emirates")
```

Now let's estimate a model without the outlier and compare to the original one:

```{r, warning=FALSE}
subset_model <- lm(democracy ~ gdp_per_capita + urbanization + energy_income_pc, data = subset_data)

stargazer(cs_model, subset_model, type = "text", report = "vcstp*",
          column.labels = c("full sample", "influential/outliers removed"))
```

In this case, significance of our coefficients is unaffects, but with a smaller $n$ it might be. We can see there is some change in coeficient values, p-values, and $R^2$.
